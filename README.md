# Capsule-Encoder-Decoder: A Method for Generalizable Building Extraction from Remote Sensing Images

It is known that due to the different acquisition conditions, remote sensing dataset over large-scale area and over long-term time series will have large variations and large statistical distribution features, which will lead to a performance drop of the deep learning model that is only trained on the source domain. To solve the problem, we propose a Capsule-Encoder-Decoder model. We use a vector named capsule to store the characteristics of the building and its parts. In our work, the encoder extracts capsules from remote sensing images. Capsules contain the information of buildings’ parts. Additionally, the decoder calculates the relationship between target building and its parts. The decoder corrects the buildings’ distribution and up-samples them to extract target buildings. Using remote sensing images in the lower Yellow River as source dataset, building extraction experiments were trained on both our method and the mainstream methods. Compared with the mainstream methods on source dataset, our method achieves convergence faster, and our method shows higher accuracy. Significantly, without fine-tuning, our method can reduce the error rates of building extraction results on an almost unfamiliar dataset. The building parts’ distribution in capsules has high-level semantic information, and capsules can describe the characteristics of buildings more comprehensively, which are more explanatory. The results prove that our method can not only effectively extract buildings but also perform great generalization from the source remote sensing dataset to another.
